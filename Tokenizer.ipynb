{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tokenizer.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dev-YJ/test/blob/master/Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEqujiH-AO-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "08b464dd-6068-4c78-e9ec-43c8832b00e9"
      },
      "source": [
        "## 1.1 실습용 영문기사 수집\n",
        "#온라인 기사를 바로 수집하여 실습데이터로 사용\n",
        "\n",
        "#https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?ss=ai-big-data#45dd5dd61f25'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "eng_news = soup.select('p') #[class=\"speakable-paragraph\"]')\n",
        "eng_text = eng_news[3].get_text()\n",
        "\n",
        "eng_text\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"And yes, she does mean everybody's job from yours to mine and onward to the role of grain farmers in Egypt, pastry chefs in Paris and dog walkers in Oregon i.e. every job. We will now be able to help direct all workers’ actions and behavior with a new degree of intelligence that comes from predictive analytics, all stemming from the AI engines we will now increasingly depend upon.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDeRBpKjBJAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "outputId": "07956431-0407-450e-838c-c0301e0f6c50"
      },
      "source": [
        "# import nltk\n",
        "# from nltk.tokenize import requests\n",
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# url = 'https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?ss=ai-big-data#45dd5dd61f25'\n",
        "# response = requests.get(url)\n",
        "# soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "# eng_news = soup.select('p') #[class=\"speakable-paragraph\"]')\n",
        "# eng_text = eng_news[3].get_text()\n",
        "\n",
        "# eng_text\n",
        "# import WordPunctTkoenizer\n",
        "# token2 = WordPunctTokenizer().Tokenize(eng_text)\n",
        "# print(token2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5790e8d17b53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?ss=ai-big-data#45dd5dd61f25'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'request'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyo9HEecCVGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "01e7c6c8-2027-4adb-9029-ab9601cc9050"
      },
      "source": [
        "#word_tokenize() : 마침표와 구두점(온점(.), 컴마(,), 물음표(?), 세미콜론(;), 느낌표(!) 등\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "token1 = word_tokenize(eng_text)\n",
        "print(token1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['And', 'yes', ',', 'she', 'does', 'mean', 'everybody', \"'s\", 'job', 'from', 'yours', 'to', 'mine', 'and', 'onward', 'to', 'the', 'role', 'of', 'grain', 'farmers', 'in', 'Egypt', ',', 'pastry', 'chefs', 'in', 'Paris', 'and', 'dog', 'walkers', 'in', 'Oregon', 'i.e', '.', 'every', 'job', '.', 'We', 'will', 'now', 'be', 'able', 'to', 'help', 'direct', 'all', 'workers', '’', 'actions', 'and', 'behavior', 'with', 'a', 'new', 'degree', 'of', 'intelligence', 'that', 'comes', 'from', 'predictive', 'analytics', ',', 'all', 'stemming', 'from', 'the', 'AI', 'engines', 'we', 'will', 'now', 'increasingly', 'depend', 'upon', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-49hLZ_CVQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# 20190513_Text Preprocessing\n",
        "# 1. 영문 전처리 실습\n",
        "# 1.1 실습용 영문기사 수집\n",
        "# 온라인 기사를 바로 수집하여 실습데이터로 사용\n",
        "\n",
        "# https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgDC80xGCVTQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4f07addf-0824-4383-ef4c-d72728c2d095"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.forbes.com/sites/adrianbridgwater/2019/04/15/what-drove-the-ai-renaissance/?ss=ai-big-data#45dd5dd61f25'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text,'html.parser')\n",
        "\n",
        "eng_news = soup.select('p') #[class=\"speakable-paragraph\"]')\n",
        "eng_text = eng_news[3].get_text()\n",
        "\n",
        "eng_text\n",
        "eng_news[2].get_text()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'IBM CEO Ginni Rometty has already proclaimed that AI will change 100 percent of jobs over the next decade.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUHQDUIvCVWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "671a56c2-7804-4b4f-8122-f8599bf4b63e"
      },
      "source": [
        "#word_tokenize() : 마침표와 구두점(온점(.), 컴마(,), 물음표(?), 세미콜론(;), 느낌표(!) 등\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "token1 = word_tokenize(eng_text)\n",
        "print(token1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['And', 'yes', ',', 'she', 'does', 'mean', 'everybody', \"'s\", 'job', 'from', 'yours', 'to', 'mine', 'and', 'onward', 'to', 'the', 'role', 'of', 'grain', 'farmers', 'in', 'Egypt', ',', 'pastry', 'chefs', 'in', 'Paris', 'and', 'dog', 'walkers', 'in', 'Oregon', 'i.e', '.', 'every', 'job', '.', 'We', 'will', 'now', 'be', 'able', 'to', 'help', 'direct', 'all', 'workers', '’', 'actions', 'and', 'behavior', 'with', 'a', 'new', 'degree', 'of', 'intelligence', 'that', 'comes', 'from', 'predictive', 'analytics', ',', 'all', 'stemming', 'from', 'the', 'AI', 'engines', 'we', 'will', 'now', 'increasingly', 'depend', 'upon', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Um49DwVDRHQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b58ab1ba-d3c6-46e4-8368-e55747d2c553"
      },
      "source": [
        "#WordPunctTokenizer() : 알파벳과 알파벳이 아닌문자를 구분하여 토큰화\n",
        "import nltk\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "token2 = WordPunctTokenizer().tokenize(eng_text)\n",
        "print(token2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['And', 'yes', ',', 'she', 'does', 'mean', 'everybody', \"'\", 's', 'job', 'from', 'yours', 'to', 'mine', 'and', 'onward', 'to', 'the', 'role', 'of', 'grain', 'farmers', 'in', 'Egypt', ',', 'pastry', 'chefs', 'in', 'Paris', 'and', 'dog', 'walkers', 'in', 'Oregon', 'i', '.', 'e', '.', 'every', 'job', '.', 'We', 'will', 'now', 'be', 'able', 'to', 'help', 'direct', 'all', 'workers', '’', 'actions', 'and', 'behavior', 'with', 'a', 'new', 'degree', 'of', 'intelligence', 'that', 'comes', 'from', 'predictive', 'analytics', ',', 'all', 'stemming', 'from', 'the', 'AI', 'engines', 'we', 'will', 'now', 'increasingly', 'depend', 'upon', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MF4dahmvCFLp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "70913cbf-cd5a-4c9f-f6dd-f5e6d3d8c5be"
      },
      "source": [
        "#TreebankWordTkoenizer() : 정규표현식에 기반한 토큰화\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "token = TreebankWordTokenizer().tokenize(eng_text)\n",
        "print(token)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "['And', 'yes', ',', 'she', 'does', 'mean', 'everybody', \"'s\", 'job', 'from', 'yours', 'to', 'mine', 'and', 'onward', 'to', 'the', 'role', 'of', 'grain', 'farmers', 'in', 'Egypt', ',', 'pastry', 'chefs', 'in', 'Paris', 'and', 'dog', 'walkers', 'in', 'Oregon', 'i.e.', 'every', 'job.', 'We', 'will', 'now', 'be', 'able', 'to', 'help', 'direct', 'all', 'workers', '’', 'actions', 'and', 'behavior', 'with', 'a', 'new', 'degree', 'of', 'intelligence', 'that', 'comes', 'from', 'predictive', 'analytics', ',', 'all', 'stemming', 'from', 'the', 'AI', 'engines', 'we', 'will', 'now', 'increasingly', 'depend', 'upon', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj9p8EMaDRMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#분리한 토큰마다 품사 부착"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqf4nhafEeAo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "1e7a76e5-292b-4327-89b6-0c857b2a789a"
      },
      "source": [
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zHGVn1WIARx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivDr9rkJEeDA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "be70cb33-5932-4081-c1d0-bbbfd8258568"
      },
      "source": [
        "taggedToken = pos_tag(token)\n",
        "print(taggedToken)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('And', 'CC'), ('yes', 'UH'), (',', ','), ('she', 'PRP'), ('does', 'VBZ'), ('mean', 'VB'), ('everybody', 'NN'), (\"'s\", 'POS'), ('job', 'NN'), ('from', 'IN'), ('yours', 'NNS'), ('to', 'TO'), ('mine', 'VB'), ('and', 'CC'), ('onward', 'VB'), ('to', 'TO'), ('the', 'DT'), ('role', 'NN'), ('of', 'IN'), ('grain', 'NN'), ('farmers', 'NNS'), ('in', 'IN'), ('Egypt', 'NNP'), (',', ','), ('pastry', 'NN'), ('chefs', 'NNS'), ('in', 'IN'), ('Paris', 'NNP'), ('and', 'CC'), ('dog', 'NN'), ('walkers', 'NNS'), ('in', 'IN'), ('Oregon', 'NNP'), ('i.e.', 'NN'), ('every', 'DT'), ('job.', 'NN'), ('We', 'PRP'), ('will', 'MD'), ('now', 'RB'), ('be', 'VB'), ('able', 'JJ'), ('to', 'TO'), ('help', 'VB'), ('direct', 'VB'), ('all', 'DT'), ('workers', 'NNS'), ('’', 'VBP'), ('actions', 'NNS'), ('and', 'CC'), ('behavior', 'NN'), ('with', 'IN'), ('a', 'DT'), ('new', 'JJ'), ('degree', 'NN'), ('of', 'IN'), ('intelligence', 'NN'), ('that', 'WDT'), ('comes', 'VBZ'), ('from', 'IN'), ('predictive', 'JJ'), ('analytics', 'NNS'), (',', ','), ('all', 'DT'), ('stemming', 'VBG'), ('from', 'IN'), ('the', 'DT'), ('AI', 'NNP'), ('engines', 'VBZ'), ('we', 'PRP'), ('will', 'MD'), ('now', 'RB'), ('increasingly', 'RB'), ('depend', 'VBP'), ('upon', 'NN'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGOgjNJgEeFi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "94d4f85a-3e1e-48ac-fc6a-d430ed77c965"
      },
      "source": [
        "#개체명 인식\n",
        "#개체가 뭔지 인식하기 위해 미리 존재하는 사전을 사용\n",
        "nltk.download('words')  \n",
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVe2KJsZEeIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#검색 엔진의 핵심기술\n",
        "from nltk import ne_chunk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uMItZyiDROt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1385
        },
        "outputId": "4df85650-8947-40e8-9940-dd14161ed465"
      },
      "source": [
        "neToken = ne_chunk(taggedToken)\n",
        "print(neToken)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  And/CC\n",
            "  yes/UH\n",
            "  ,/,\n",
            "  she/PRP\n",
            "  does/VBZ\n",
            "  mean/VB\n",
            "  everybody/NN\n",
            "  's/POS\n",
            "  job/NN\n",
            "  from/IN\n",
            "  yours/NNS\n",
            "  to/TO\n",
            "  mine/VB\n",
            "  and/CC\n",
            "  onward/VB\n",
            "  to/TO\n",
            "  the/DT\n",
            "  role/NN\n",
            "  of/IN\n",
            "  grain/NN\n",
            "  farmers/NNS\n",
            "  in/IN\n",
            "  (GPE Egypt/NNP)\n",
            "  ,/,\n",
            "  pastry/NN\n",
            "  chefs/NNS\n",
            "  in/IN\n",
            "  (GPE Paris/NNP)\n",
            "  and/CC\n",
            "  dog/NN\n",
            "  walkers/NNS\n",
            "  in/IN\n",
            "  (GPE Oregon/NNP)\n",
            "  i.e./NN\n",
            "  every/DT\n",
            "  job./NN\n",
            "  We/PRP\n",
            "  will/MD\n",
            "  now/RB\n",
            "  be/VB\n",
            "  able/JJ\n",
            "  to/TO\n",
            "  help/VB\n",
            "  direct/VB\n",
            "  all/DT\n",
            "  workers/NNS\n",
            "  ’/VBP\n",
            "  actions/NNS\n",
            "  and/CC\n",
            "  behavior/NN\n",
            "  with/IN\n",
            "  a/DT\n",
            "  new/JJ\n",
            "  degree/NN\n",
            "  of/IN\n",
            "  intelligence/NN\n",
            "  that/WDT\n",
            "  comes/VBZ\n",
            "  from/IN\n",
            "  predictive/JJ\n",
            "  analytics/NNS\n",
            "  ,/,\n",
            "  all/DT\n",
            "  stemming/VBG\n",
            "  from/IN\n",
            "  the/DT\n",
            "  (ORGANIZATION AI/NNP)\n",
            "  engines/VBZ\n",
            "  we/PRP\n",
            "  will/MD\n",
            "  now/RB\n",
            "  increasingly/RB\n",
            "  depend/VBP\n",
            "  upon/NN\n",
            "  ./.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjGY_TjrGU9S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "7795088b-0c28-4ece-d2e9-eb6649cc8ba1"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "\n",
        "print(\"running -> \" + ps.stem(\"running\"))\n",
        "print(\"beautiful -> \" + ps.stem(\"beautiful\"))\n",
        "print(\"believes -> \" + ps.stem(\"believes\"))\n",
        "print(\"using -> \" + ps.stem(\"using\"))\n",
        "print(\"conversation -> \" + ps.stem(\"conversation\"))\n",
        "print(\"organization -> \" + ps.stem(\"organization\"))\n",
        "print(\"studies -> \" + ps.stem(\"studies\"))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running -> run\n",
            "beautiful -> beauti\n",
            "believes -> believ\n",
            "using -> use\n",
            "conversation -> convers\n",
            "organization -> organ\n",
            "studies -> studi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuqXZCmRIAXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2faad29f-9ca6-4cc7-e9b6-269597decf3d"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpxAMX3NIAUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "2d23dba0-35f2-4792-c0ff-b00229a4537f"
      },
      "source": [
        "#표제어 추출\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wl = WordNetLemmatizer()\n",
        "\n",
        "print(\"running -> \" + wl.lemmatize(\"running\"))\n",
        "print(\"beautiful -> \" + wl.lemmatize(\"beautiful\"))\n",
        "print(\"believes -> \" + wl.lemmatize(\"believes\"))\n",
        "print(\"using -> \" + wl.lemmatize(\"using\"))\n",
        "print(\"conversation -> \" + wl.lemmatize(\"conversation\"))\n",
        "print(\"organization -> \" + wl.lemmatize(\"organization\"))\n",
        "print(\"studies -> \" + wl.lemmatize(\"studies\"))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running -> running\n",
            "beautiful -> beautiful\n",
            "believes -> belief\n",
            "using -> using\n",
            "conversation -> conversation\n",
            "organization -> organization\n",
            "studies -> study\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NECdaQc9IAZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#불용어 처리\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhSuiL1IKD1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stopPos = ['IN','CC','UH','TO','MD','DT','VBZ','VBP']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLJDx3t4KE39",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1097
        },
        "outputId": "4c9ad989-16bb-4120-fafc-6895e7b984bf"
      },
      "source": [
        "#최빈어 조회, 최빈어를 조회하여 불용어 제거 대상을 선정\n",
        "from collections import Counter\n",
        "Counter(taggedToken).most_common()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((',', ','), 3),\n",
              " (('from', 'IN'), 3),\n",
              " (('to', 'TO'), 3),\n",
              " (('and', 'CC'), 3),\n",
              " (('in', 'IN'), 3),\n",
              " (('the', 'DT'), 2),\n",
              " (('of', 'IN'), 2),\n",
              " (('will', 'MD'), 2),\n",
              " (('now', 'RB'), 2),\n",
              " (('all', 'DT'), 2),\n",
              " (('And', 'CC'), 1),\n",
              " (('yes', 'UH'), 1),\n",
              " (('she', 'PRP'), 1),\n",
              " (('does', 'VBZ'), 1),\n",
              " (('mean', 'VB'), 1),\n",
              " (('everybody', 'NN'), 1),\n",
              " ((\"'s\", 'POS'), 1),\n",
              " (('job', 'NN'), 1),\n",
              " (('yours', 'NNS'), 1),\n",
              " (('mine', 'VB'), 1),\n",
              " (('onward', 'VB'), 1),\n",
              " (('role', 'NN'), 1),\n",
              " (('grain', 'NN'), 1),\n",
              " (('farmers', 'NNS'), 1),\n",
              " (('Egypt', 'NNP'), 1),\n",
              " (('pastry', 'NN'), 1),\n",
              " (('chefs', 'NNS'), 1),\n",
              " (('Paris', 'NNP'), 1),\n",
              " (('dog', 'NN'), 1),\n",
              " (('walkers', 'NNS'), 1),\n",
              " (('Oregon', 'NNP'), 1),\n",
              " (('i.e.', 'NN'), 1),\n",
              " (('every', 'DT'), 1),\n",
              " (('job.', 'NN'), 1),\n",
              " (('We', 'PRP'), 1),\n",
              " (('be', 'VB'), 1),\n",
              " (('able', 'JJ'), 1),\n",
              " (('help', 'VB'), 1),\n",
              " (('direct', 'VB'), 1),\n",
              " (('workers', 'NNS'), 1),\n",
              " (('’', 'VBP'), 1),\n",
              " (('actions', 'NNS'), 1),\n",
              " (('behavior', 'NN'), 1),\n",
              " (('with', 'IN'), 1),\n",
              " (('a', 'DT'), 1),\n",
              " (('new', 'JJ'), 1),\n",
              " (('degree', 'NN'), 1),\n",
              " (('intelligence', 'NN'), 1),\n",
              " (('that', 'WDT'), 1),\n",
              " (('comes', 'VBZ'), 1),\n",
              " (('predictive', 'JJ'), 1),\n",
              " (('analytics', 'NNS'), 1),\n",
              " (('stemming', 'VBG'), 1),\n",
              " (('AI', 'NNP'), 1),\n",
              " (('engines', 'VBZ'), 1),\n",
              " (('we', 'PRP'), 1),\n",
              " (('increasingly', 'RB'), 1),\n",
              " (('depend', 'VBP'), 1),\n",
              " (('upon', 'NN'), 1),\n",
              " (('.', '.'), 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O__oyr79KE6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "263f70d5-ce75-4277-d966-0e6cf4dc02dd"
      },
      "source": [
        "stopWord = [',','be','able']\n",
        "word = []\n",
        "for tag in taggedToken:\n",
        "    if tag[1] not in stopPos:\n",
        "        word.append(tag[0])\n",
        "print(word)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[',', 'she', 'mean', 'everybody', \"'s\", 'job', 'yours', 'mine', 'onward', 'role', 'grain', 'farmers', 'Egypt', ',', 'pastry', 'chefs', 'Paris', 'dog', 'walkers', 'Oregon', 'i.e.', 'job.', 'We', 'now', 'be', 'able', 'help', 'direct', 'workers', 'actions', 'behavior', 'new', 'degree', 'intelligence', 'that', 'predictive', 'analytics', ',', 'stemming', 'AI', 'we', 'now', 'increasingly', 'upon', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZdoKa34KE8-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "f87d89ad-2f4a-4988-b7e6-e8f965195aa3"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('words')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k4FKSlzKE_1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rra9Ldk9IAc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}